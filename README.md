# Sign Language Recognition System ğŸ¤Ÿ

A machine learningâ€“based Sign Language Recognition system that detects and interprets hand gestures into meaningful text using computer vision and deep learning techniques. This project aims to improve communication accessibility for individuals with hearing or speech impairments.

---

## ğŸ¯ Objective
To build a real-time sign language recognition system capable of accurately identifying hand gestures and converting them into understandable outputs using image processing and trained ML models.

---

## ğŸš€ Features
- Real-time hand gesture detection  
- Custom dataset creation  
- Landmark extraction for gesture recognition  
- Trained deep learning model  
- Modular and scalable architecture  
- Supports multiple sign categories (e.g., *I Love You*, *Thank You*)

---

## ğŸ§  Tech Stack
- **Language:** Python  
- **Libraries & Tools:**  
  - OpenCV  
  - MediaPipe  
  - TensorFlow / Keras  
  - NumPy  
  - Pandas  
- **Model Formats:** `.h5`, `.tflite`

---




## â–¶ï¸ Demo Video
ğŸ”— https://youtu.be/zJlaSCoxN0U?si=kcWqOq2c-tGtwqfp

---

## ğŸ“Š Results
- Successfully detects and classifies predefined sign language gestures  
- Reliable real-time performance  
- Consistent accuracy across supported signs  

---

## ğŸ§© Future Scope
- Add more sign language categories  
- Improve accuracy using a larger and more diverse dataset  
- Deploy as a web or mobile application  
- Integrate speech output for real-time communication  

---

## ğŸ‘¤ Author
**Astha Dakhinray**  
BTech CSE (AIML)  
Focused on AI-driven accessibility and real-world impact projects

---

## ğŸ“œ License
This project is intended for educational and research purposes.


